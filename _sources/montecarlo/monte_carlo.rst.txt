.. _montecarlo_class:

Monte Carlo
-----------

.. py:class:: MonteCarlo

    Class that allows the statistical comparison of several models on the same dataset

    Example::

        # Assume you already have complex data 'x' with its labels 'y'... and 3 Cvnn models.

        montecarlo = MonteCarlo()
        montecarlo.add_model(model1)
        montecarlo.add_model(model2)
        montecarlo.add_model(model3)

        montecarlo.run(x, y)

    A file :code:`./log/monte_carlo_summary.xlsx` is generated the first call to `run` method. 
    All following calls will add a row to that same file with each run information to keep track of the results and its configuration.
    
    This code will also generate files into :code:`./log/montecarlo/date/of/run/`

        - :code:`run_data.csv`: Full information of performance of iteration of each model at each epoch
        - :code:`<model.name>_statistical_result.csv`: Statistical results of all iterations of each model per epoch (mean, median, std, etc)
        - :code:`models_details.json`: A full detailed description of each model to be trained
        - (Optional) :code:`run_summary.txt`: User friendly summary of the run models and data
        - (Optional) :code:`plot/` folder with the corresponding plots generated by :code:`MonteCarloAnalyzer.do_all()`

.. Note:: To see how to create the Optional outputs refer to :ref:`output-files`.

    
.. py:method:: add_model(self, model: keras.Model)

        Adds a :code:`keras.Model` to the list to then comparate between them

.. py:method:: run(self, x, y, data_summary='', real_cast_modes=None, validation_split=0.2, validation_data=None, test_data=None, iterations=100, epochs=10, batch_size=100, shuffle=False, display_freq=1)

    This function is used to compare all models added with :code:`self.add_model` method.
    Runs the iteration dataset :code:`(x, y)`.

    #. It then runs a monte carlo simulation of several iterations of each added model.
    #. An excel file will be created on :code:`./logs/` folder on the first time it runs. All following runs will add a row to the file with the run information to keep track of the results and its configuration.
    #. Saves several files into :code:`./logs/montecarlo/<year>/<month>/<day>/run_<time>/`
        #. :code:`run_data.csv`: Full information of performance of iteration of each model at each epoch
        #. :code:`<model.name>_statistical_result.csv`: Statistical results of all iterations of each model per epoch (mean, median, std, etc)
        #. :code:`models_details.json`: A full detailed description of each model to be trained
        #. (Optional) :code:`run_summary.txt`: User friendly summary of the run models and data
        #. (Optional) :code:`plot/` folder with the corresponding plots generated by :code:`MonteCarloAnalyzer.do_all()`

    :param x: Input data. It could be:
        - A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs).
        - A :code:`TensorFlow tensor`, or a list of tensors (in case the model has multiple inputs).
        - A :code:`tf.data dataset`. Should return a tuple (inputs, targets). Preferred data type (less overhead).
    :param y: Labels/Target data. Like the input data x, it could be either Numpy array(s) or TensorFlow tensor(s).
        If x is a dataset then y will be ignored.
    :param data_summary:  (String) Dataset name to keep track of it
    :param real_cast_modes: :code:`mode` parameter used by :ref:`transform-to-real-label` to be used when the model to train is real-valued. One of the following:
            
        - String with the :code:`mode` listed in :code:`cvnn.utils.transform_to_real` to be used by all the real-valued models to cast complex data to real.
        - List or Tuple of strings: Same size of :code:`self.models`. Mode to cast complex data to real for each model in :code:`self.model`. :code:`real_cast_modes[i]` will indicate how to cast data for :code:`self.models[i]` (ignored when model is complex)
    
    :param validation_split: Float between 0 and 1.
        Percentage of the input data to be used as test set (the rest will be use as train set)
        Default: 0.0 (No validation set).
        This input is ignored if validation_data is given.
    :param validation_data: A tuple :code:`(x_val, y_val)` of Numpy arrays or tensors. Preferred data type (less overhead).
        Data on which to evaluate the loss and any model metrics at the end of each epoch.
        The model will not be trained on this data. This parameter takes precedence over :code:`validation_split`.
    :param test_data: (Optional) tuple :code:`(x_test, y_test)` of Numpy arrays or tensors.
        Data on which to evaluate the loss and any model metrics at the end of a model training. 
        The model will not be trained on this data. 
        If test data is not None (default) it will generate a file called :code:`test_results.csv` with the statistical results from the test data.
    :param iterations: Number of iterations to be done for each model
    :param epochs: Number of epochs for each iteration
    :param batch_size: Batch size at each iteration
    :param display_freq: Integer (Default 1)
        Frequency on terms of epochs before saving information and running a checkpoint.
    :param shuffle: (Boolean) Whether to shuffle the training data before each epoch.
    :return: (string) Full path to the :code:`run_data.csv` generated file.
        It can be used by :code:`cvnn.data_analysis.SeveralMonteCarloComparison` to compare several runs.