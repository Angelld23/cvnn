.. _montecarlo_class:

Monte Carlo
===========

.. py:class:: MonteCarlo

    Class that allows the statistical comparison of several models on the same dataset

    Example::

        # Assume you already have complex data 'x' with its labels 'y'... and 3 Cvnn models.

        montecarlo = MonteCarlo()
        montecarlo.add_model(model1)
        montecarlo.add_model(model1)
        montecarlo.add_model(model1)

        montecarlo.run(x, y)

    This code will generate files into :code:`./log/montecarlo/date/of/run/`

        - :code:`run_summary.txt`: Summary of the run models and data
        - :code:`run_data.csv`: Full information of performance of iteration of each model at each epoch
        - :code:`<model.name>_statistical_result.csv`: Statistical results of all iterations of each model per epoch (mean, median, std, etc)
        - (Optional) :code:`plot/` folder with the corresponding plots generated by :code:`MonteCarloAnalyzer.do_all()`

    
.. py:method:: add_model(self, model: CvnnModel)

        Adds a cvnn.CvnnModel to the list to then comparate between them

.. py:method:: run(self, x, y, data_summary='', polar=False, do_conf_mat=True, validation_split=0.2, validation_data=None, iterations=100, epochs=10, batch_size=100, shuffle=False, debug=False, display_freq=1, checkpoints=False)

    This function is used to compare all models added with `self.add_model` method.
    Runs the iteration dataset (x, y).

    1. It then runs a monte carlo simulation of several iterations of both CVNN and an equivalent RVNN model.
    2. Saves several files into ./log/montecarlo/date/of/run/
        2.1. run_summary.txt: Summary of the run models and data
        2.2. run_data.csv: Full information of performance of iteration of each model at each epoch
        2.3. <model.name>_network_statistical_result.csv: Statistical results of all iterations of CVNN per epoch
        2.4. (Optional) `plot/` folder with the corresponding plots generated by MonteCarloAnalyzer.do_all()

    :param x: Input data. It could be:
        - A Numpy array (or array-like), or a list of arrays (in case the model has multiple inputs).
        - A TensorFlow tensor, or a list of tensors (in case the model has multiple inputs).
        - A tf.data dataset. Should return a tuple (inputs, targets). Preferred data type (less overhead).
    :param y: Labels/Target data. Like the input data x, it could be either Numpy array(s) or TensorFlow tensor(s).
        If f x is a dataset then y will be ignored (default None)
    :param data_summary:  (String) Dataset name to keep track of it
    :param polar: (Boolean) If the model is real.
        Separate the complex data into real and imaginary part (polar = False) or amplitude and phase (polar = True)
    :param do_conf_mat: Generate a confusion matrix based on results.
    :param validation_split: Float between 0 and 1.
        Percentage of the input data to be used as test set (the rest will be use as train set)
        Default: 0.0 (No validation set).
        This input is ignored if validation_data is given.
    :param validation_data: Data on which to evaluate the loss and any model metrics at the end of each epoch.
        The model will not be trained on this data. This parameter takes precedence over validation_split.
        It can be:
            - tuple (x_val, y_val) of Numpy arrays or tensors. Preferred data type (less overhead).
            - A tf.data dataset.
    :param iterations: Number of iterations to be done for each model
    :param epochs: Number of epochs for each iteration
    :param batch_size: Batch size at each iteration
    :param display_freq: Integer (Default 1)
        Frequency on terms of epochs before saving information and running a checkpoint.
    :param shuffle: (Boolean) Whether to shuffle the training data before each epoch.
    :param debug:
    :param checkpoints:
    :return: (string) Full path to the run_data.csv generated file.
        It can be used by cvnn.data_analysis.SeveralMonteCarloComparison to compare several runs.


.. _real_vs_complex:

Real Vs Complex
---------------

.. py:class:: RealVsComplex(MonteCarlo)

    Inherits from MonteCarlo.

    Compares a complex model with it's real equivalent.

    Example usage::

        # Assume you already have complex data 'x' with its labels 'y'... and a Cvnn model.

        montecarlo = RealVsComplex(complex_model)
        montecarlo.run(x, y)


.. py:method:: __init__(self, complex_model, capacity_equivalent=True, equiv_technique='ratio')

    Used to compare a single Complex Model given as a parameter. The Code will generate it's real equivalent and compre both of them.

    :param complex_model: cvnn.CvnnModel
    :param capacity_equivalent: An equivalent model can be equivalent in terms of layer neurons or trainable parameters (capacity equivalent according to `this paper <https://arxiv.org/abs/1811.12351>`_
        - True, it creates a capacity-equivalent model in terms of trainable parameters
        - False, it will double all layer size (except the last one if classifier=True)
    :param equiv_technique: Used to define the strategy of the capacity equivalent model.
        This parameter is ignored if capacity_equivalent=False
        - 'ratio': :code:`neurons_real_valued_layer[i] = r * neurons_complex_valued_layer[i]`, 'r' constant for all 'i'
        - 'alternate': Method described in `this paper <https://arxiv.org/abs/1811.12351>`_ where one alternates between multiplying by 2 or 1. Special case on the middle is treated as a compromise between the two.

.. _helper_function

Other Helper function
---------------------

.. py:method:: mlp_run_real_comparison_montecarlo(dataset: cvnn.dataset.Dataset, open_dataset=None, iterations=1000, epochs=150, batch_size=100, display_freq=1, optimizer='sgd', shape_raw=None, activation='cart_relu', debug=False, polar=False, do_all=True, dropout=0.5, validation_split=0.2, validation_data=None, capacity_equivalent=True, equiv_technique='ratio', do_conf_mat=True)

    This function is used to compare CVNN vs RVNN performance over statistical non-circular data.
    1. Automatically creates two Multi-Layer Perceptrons (MLP), one complex and one real.
    2. Runs simulation and compares them.
    3. Saves several files into ./log/montecarlo/date/of/run/
        3.1. :code:`run_summary.txt`: Summary of the run models and data
        3.2. :code:`run_data.csv`: Full information of performance of iteration of each model at each epoch
        3.3. :code:`complex_network_statistical_result.csv`: Statistical results of all iterations of CVNN per epoch
        3.4. :code:`complex_network_statistical_result.csv`: Statistical results of all iterations of RVNN per epoch
        3.5. (Optional) :code:`plot/` folder with the corresponding plots generated by :code:`MonteCarloAnalyzer.do_all()`

    :param dataset: cvnn.dataset.Dataset with the dataset to be used on the training
    :param open_dataset: (:code:`None`)
        If dataset is saved inside a folder and must be opened, path of the Dataset to be opened. Else None (default)
    :param iterations: Number of iterations to be done for each model
    :param epochs: Number of epochs for each iteration
    :param batch_size: Batch size at each iteration
    :param display_freq: Frequency in terms of epochs of when to do a checkpoint.
    :param optimizer: Optimizer to be used. Keras optimizers are not allowed.
            Can be either cvnn.optimizers.Optimizer or a string listed in opt_dispatcher.
    :param shape_raw: List of sizes of each hidden layer.
        For example :code:`[64]` will generate a CVNN with one hidden layer of size 64.
        Default :code:`None` will default to example.
    :param activation: Activation function to be used at each hidden layer
    :param debug:
    :param polar: Boolean weather the RVNN should receive real and imaginary part (False) or amplitude and phase (True)
    :param do_all: If true (default) it creates a :code:`plot/` folder with the plots generated by MonteCarloAnalyzer.do_all()
    :param dropout: (float) Dropout to be used at each hidden layer. If :code:`None` it will not use any dropout.
    :param validation_split: Float between 0 and 1.
            Percentage of the input data to be used as test set (the rest will be use as train set)
            Default: 0.0 (No validation set).
            This input is ignored if validation_data is given.
        :param validation_data: Data on which to evaluate the loss and any model metrics at the end of each epoch.
            The model will not be trained on this data. This parameter takes precedence over validation_split.
            It can be:
                - tuple :code:`(x_val, y_val)` of Numpy arrays or tensors. Preferred data type (less overhead).
                - A :code:`tf.data dataset`.
    :param capacity_equivalent: An equivalent model can be equivalent in terms of layer neurons or
                        trainable parameters (capacity equivalent according to: `this paper <https://arxiv.org/abs/1811.12351>`_
            - True, it creates a capacity-equivalent model in terms of trainable parameters
            - False, it will double all layer size (except the last one if classifier=True)
    :param equiv_technique: Used to define the strategy of the capacity equivalent model.
        This parameter is ignored if :code:`capacity_equivalent=False`
        - 'ratio': :code:`neurons_real_valued_layer[i] = r * neurons_complex_valued_layer[i]`, 'r' constant for all 'i'
        - 'alternate': Method described in `this paper <https://arxiv.org/abs/1811.12351>`_ where one alternates between
                multiplying by 2 or 1. Special case on the middle is treated as a compromise between the two.
    :param do_conf_mat: Generate a confusion matrix based on results.
    :return: (string) Full path to the run_data.csv generated file.
        It can be used by :code:`cvnn.data_analysis.SeveralMonteCarloComparison` to compare several runs.

