

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Complex input, real output &mdash; cvnn 0.1.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ReLU-based" href="relu.html" />
    <link rel="prev" title="TYPE A: Cartesian form" href="types.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> cvnn
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../layers.html">Complex Layers</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../act_fun.html">Activation Functions</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="types.html">TYPE A: Cartesian form</a></li>
<li class="toctree-l2"><a class="reference internal" href="types.html#type-b-polar-form">TYPE B: Polar form</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Complex input, real output</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#softmax-based">Softmax Based</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="relu.html">ReLU-based</a></li>
<li class="toctree-l2"><a class="reference internal" href="mvn_activation.html">Phasor activation functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="etf.html">Elementary Transcentental Functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../initializers.html">Initializers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../montecarlo.html">Monte Carlo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data_analysis.html">Data Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code_examples.html">Code Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../results.html">Publication results</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html">About Me</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">cvnn</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../act_fun.html">Activation Functions</a> &raquo;</li>
        
      <li>Complex input, real output</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/activations/real_output.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="complex-input-real-output">
<h1>Complex input, real output<a class="headerlink" href="#complex-input-real-output" title="Permalink to this headline">¶</a></h1>
<dl class="py method">
<dt id="convert_to_real_with_abs">
<code class="sig-name descname">convert_to_real_with_abs</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">z</span></em><span class="sig-paren">)</span><a class="headerlink" href="#convert_to_real_with_abs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<p>Applies the absolute value and returns a real-valued output.</p>
<dl class="field-list simple">
<dt class="field-odd">param z</dt>
<dd class="field-odd"><p>Input tensor.</p>
</dd>
<dt class="field-even">return</dt>
<dd class="field-even"><p>Real-valued tensor of the applied activation function</p>
</dd>
</dl>
<div class="section" id="softmax-based">
<h2>Softmax Based<a class="headerlink" href="#softmax-based" title="Permalink to this headline">¶</a></h2>
<p>The following function will always output a real-valued output even if the input is complex.</p>
<p>All the functions use the <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/activations/softmax">softmax</a> function as a base.
If the input is real-valued they all apply the conventional softmax function to the data.
The softmax activation function transforms the outputs so that all values are in range (0, 1) and sum to 1.
It is often used as the activation for the last layer of a classification network because the result could be
interpreted as a probability distribution.
The softmax of x is calculated by:</p>
<div class="math notranslate nohighlight">
\[\sigma = \frac{e^x}{\textrm{tf.reduce_sum}(e^x)}\]</div>
<dl class="py method">
<dt id="softmax_real_with_abs">
<code class="sig-name descname">softmax_real_with_abs</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">z</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">- 1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#softmax_real_with_abs" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the  function to the modulus of z (only if z is complex).</p>
<div class="math notranslate nohighlight">
\[out = \sigma(|z|)\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> – Input tensor.</p></li>
<li><p><strong>axis</strong> – (Optional) Integer, axis along which the softmax normalization is applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Real-valued tensor of the applied activation function</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="softmax_real_with_avg">
<code class="sig-name descname">softmax_real_with_avg</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">z</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">- 1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#softmax_real_with_avg" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the function to the real and imaginary part of z separately and then averages it.</p>
<div class="math notranslate nohighlight">
\[out = \frac{\sigma(x) + \sigma(y)}{2}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> – Input tensor.</p></li>
<li><p><strong>axis</strong> – (Optional) Integer, axis along which the softmax normalization is applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Real-valued tensor of the applied activation function</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="softmax_real_with_mult">
<code class="sig-name descname">softmax_real_with_mult</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">z</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">- 1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#softmax_real_with_mult" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the function to the real and imaginary part of z separately and then multiplies them.</p>
<div class="math notranslate nohighlight">
\[out = \sigma(x) * \sigma(y)\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> – Input tensor.</p></li>
<li><p><strong>axis</strong> – (Optional) Integer, axis along which the softmax normalization is applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Real-valued tensor of the applied activation function</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="softmax_of_softmax_real_with_mult">
<code class="sig-name descname">softmax_of_softmax_real_with_mult</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">z</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">- 1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#softmax_of_softmax_real_with_mult" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the function to the real and imaginary part of z separately and then applies the function again on the product of them.</p>
<div class="math notranslate nohighlight">
\[out = \sigma(\sigma(x) * \sigma(y))\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> – Input tensor.</p></li>
<li><p><strong>axis</strong> – (Optional) Integer, axis along which the softmax normalization is applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Real-valued tensor of the applied activation function</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="softmax_of_softmax_real_with_avg">
<code class="sig-name descname">softmax_of_softmax_real_with_avg</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">z</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">- 1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#softmax_of_softmax_real_with_avg" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the function to the real and imaginary part of z separately and then applies the function again on the sum of them.</p>
<div class="math notranslate nohighlight">
\[out = \sigma(\sigma(x) + \sigma(y))\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> – Input tensor.</p></li>
<li><p><strong>axis</strong> – (Optional) Integer, axis along which the softmax normalization is applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Real-valued tensor of the applied activation function</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="softmax_real_with_polar">
<code class="sig-name descname">softmax_real_with_polar</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">z</span></em>, <em class="sig-param"><span class="n">axis</span><span class="o">=</span><span class="default_value">- 1</span></em><span class="sig-paren">)</span><a class="headerlink" href="#softmax_real_with_polar" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the function to the amplitude and phase of z separately and then averages them.</p>
<div class="math notranslate nohighlight">
\[out = \frac{\sigma(|z|) + \sigma(\phi_z))}{2}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> – Input tensor.</p></li>
<li><p><strong>axis</strong> – (Optional) Integer, axis along which the softmax normalization is applied.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Real-valued tensor of the applied activation function</p>
</dd>
</dl>
</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="relu.html" class="btn btn-neutral float-right" title="ReLU-based" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="types.html" class="btn btn-neutral float-left" title="TYPE A: Cartesian form" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, J Agustin BARRACHINA

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>