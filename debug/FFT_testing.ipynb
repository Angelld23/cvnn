{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from cvnn.layers import Convolutional\n",
    "from pdb import set_trace\n",
    "import sys\n",
    "from scipy import signal\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both TF and NP results calculate fft the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'complex128'>\n",
      "False\n",
      "[ 50005000.        +50005000.j\n",
      " -15920493.78559075+15910493.78559075j\n",
      "  -7962746.10739719 +7952746.10739719j\n",
      "  -5310163.19893343 +5300163.19893342j\n",
      "  -3983871.48290206 +3973871.48290206j\n",
      "  -3188096.2438436  +3178096.2438436j\n",
      "  -2657579.24327153 +2647579.24327153j\n",
      "  -2278638.37897732 +2268638.37897732j\n",
      "  -1994432.59985672 +1984432.59985672j\n",
      "  -1773383.54418512 +1763383.54418512j]\n",
      "[ 50005000.        +50005000.j\n",
      " -15920493.78559075+15910493.78559075j\n",
      "  -7962746.10739719 +7952746.10739719j\n",
      "  -5310163.19893342 +5300163.19893342j\n",
      "  -3983871.48290206 +3973871.48290206j\n",
      "  -3188096.2438436  +3178096.2438436j\n",
      "  -2657579.24327152 +2647579.24327152j\n",
      "  -2278638.37897732 +2268638.37897732j\n",
      "  -1994432.59985672 +1984432.59985672j\n",
      "  -1773383.54418512 +1763383.54418512j]\n",
      "[ True False  True ... False False False]\n",
      "(1.862645149230957e-09+0j)\n"
     ]
    }
   ],
   "source": [
    "aaa = np.linspace(1.0, 10000.0, 10000)\n",
    "x = aaa + 1j * aaa\n",
    "x_tensor = tf.convert_to_tensor(x)\n",
    "\n",
    "tf_fft = tf.signal.fft(x_tensor)\n",
    "np_fft = np.fft.fft(x)\n",
    "\n",
    "print(tf_fft.dtype)\n",
    "print(np.all(tf_fft.numpy() == np_fft))  # Results are not exactly the same (but fair enough)\n",
    "print(tf_fft.numpy()[:10])\n",
    "print(np_fft[:10])\n",
    "print(tf_fft.numpy() == np_fft)\n",
    "print((tf_fft.numpy() - np_fft)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_real:  \t[ 0  1  2  4  6  8 10 12 14 16  8  9]\n",
      "convolve:\t[ 0  1  2  4  6  8 10 12 14 16  8  9]\n",
      "Manual nn conv: [2, 4, 6, 8, 10, 12, 14, 16]\n",
      "Manual fft conv:[2, 4, 6, 8, 10, 12, 14, 16]\n"
     ]
    }
   ],
   "source": [
    "b = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "c = [1, 0, 1]\n",
    "\n",
    "b_pad = tf.cast(tf.pad(b, tf.constant([[0, 2]])), tf.complex64)  # Full padding\n",
    "I = tf.signal.fft(tf.cast(b_pad, tf.complex64))\n",
    "paddings = tf.constant([[0, 9]])\n",
    "c_pad = tf.cast(tf.pad(c, paddings), tf.complex64)\n",
    "C = tf.signal.fft(c_pad)\n",
    "F = tf.math.multiply(I, C)\n",
    "f = tf.signal.ifft(F)\n",
    "f_real = tf.cast(f, tf.int32)\n",
    "\n",
    "# print(\"std_out: \" + str(std_out))\n",
    "print(\"f_real:  \\t\" + str(f_real.numpy()))\n",
    "print(\"convolve:\\t\" + str(np.convolve(b, c)))\n",
    "\n",
    "manual_conv = []\n",
    "for i in range(len(b)-len(c)+1):\n",
    "    manual_conv.append(np.sum(tf.math.multiply(c, b[i:i+3]).numpy()))\n",
    "print(\"Manual nn conv: \" + str(manual_conv))\n",
    "\n",
    "c.reverse()\n",
    "manual_conv = []\n",
    "for i in range(len(b)-len(c)+1):\n",
    "    manual_conv.append(np.sum(tf.math.multiply(c, b[i:i+3]).numpy()))\n",
    "print(\"Manual fft conv:\" + str(manual_conv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m2020-11-16 18:55:05,977 — WARNING - layers::_verify_inputs line 569 — input dtype (<dtype: 'float64'>) not what expected (<class 'numpy.float32'>). Attempting cast...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual_conv: \n",
      "[[[-10. -10.   0.  10.  10.   0.   0.   0.]\n",
      "  [-20. -20.   0.  20.  20.   0.   0.   0.]\n",
      "  [-30. -30.   0.  30.  30.   0.   0.   0.]\n",
      "  [-30. -30.   0.  30.  30.   0.   0.   0.]\n",
      "  [-30. -30.   0.  30.  30.   0.   0.   0.]\n",
      "  [-30. -30.   0.  30.  30.   0.   0.   0.]\n",
      "  [-20. -20.   0.  20.  20.   0.   0.   0.]\n",
      "  [-10. -10.   0.  10.  10.   0.   0.   0.]]]\n",
      "tf_nn_conv2d: \n",
      "[[-20.   0.  20.  20.   0.   0.]\n",
      " [-30.   0.  30.  30.   0.   0.]\n",
      " [-30.   0.  30.  30.   0.   0.]\n",
      " [-30.   0.  30.  30.   0.   0.]\n",
      " [-30.   0.  30.  30.   0.   0.]\n",
      " [-20.   0.  20.  20.   0.   0.]]\n",
      "tf.Tensor(\n",
      "[[180.          +0.j         102.42640687-102.42640687j\n",
      "   -0.         -60.j          17.57359313 +17.57359313j\n",
      "   60.          +0.j          17.57359313 -17.57359313j\n",
      "    0.         +60.j         102.42640687+102.42640687j]\n",
      " [-21.21320344 -51.21320344j -41.21320344 -17.07106781j\n",
      "  -17.07106781  +7.07106781j   2.92893219  -7.07106781j\n",
      "   -7.07106781 -17.07106781j  -7.07106781  -2.92893219j\n",
      "   17.07106781  -7.07106781j  17.07106781 -41.21320344j]\n",
      " [ 30.         -30.j           0.         -34.14213562j\n",
      "  -10.         -10.j           5.85786438  -0.j\n",
      "   10.         -10.j          -0.          -5.85786438j\n",
      "   10.         +10.j          34.14213562  +0.j        ]\n",
      " [ 21.21320344  +8.78679656j  17.07106781  -7.07106781j\n",
      "    2.92893219  -7.07106781j   1.21320344  +2.92893219j\n",
      "    7.07106781  +2.92893219j   2.92893219  -1.21320344j\n",
      "   -2.92893219  +7.07106781j   7.07106781 +17.07106781j]\n",
      " [  0.          +0.j           0.          +0.j\n",
      "    0.          +0.j           0.          +0.j\n",
      "    0.          +0.j           0.          +0.j\n",
      "    0.          +0.j           0.          +0.j        ]\n",
      " [ 21.21320344  -8.78679656j   7.07106781 -17.07106781j\n",
      "   -2.92893219  -7.07106781j   2.92893219  +1.21320344j\n",
      "    7.07106781  -2.92893219j   1.21320344  -2.92893219j\n",
      "    2.92893219  +7.07106781j  17.07106781  +7.07106781j]\n",
      " [ 30.         +30.j          34.14213562  -0.j\n",
      "   10.         -10.j          -0.          +5.85786438j\n",
      "   10.         +10.j           5.85786438  +0.j\n",
      "  -10.         +10.j           0.         +34.14213562j]\n",
      " [-21.21320344 +51.21320344j  17.07106781 +41.21320344j\n",
      "   17.07106781  +7.07106781j  -7.07106781  +2.92893219j\n",
      "   -7.07106781 +17.07106781j   2.92893219  +7.07106781j\n",
      "  -17.07106781  -7.07106781j -41.21320344 +17.07106781j]], shape=(8, 8), dtype=complex128)\n",
      "manual_fft_conv: tf.Tensor(\n",
      "[[ 10  10   0 -10 -10   0   0   0]\n",
      " [ 20  20   0 -20 -20   0   0   0]\n",
      " [ 30  30   0 -30 -30   0   0   0]\n",
      " [ 30  30   0 -30 -30   0   0   0]\n",
      " [ 30  30   0 -30 -30   0   0   0]\n",
      " [ 30  30   0 -30 -30   0   0   0]\n",
      " [ 20  20   0 -20 -20   0   0   0]\n",
      " [ 10  10   0 -10 -10   0   0   0]], shape=(8, 8), dtype=int32)\n",
      "sp_fft_conv_full:\n",
      "[[ 10  10   0 -10 -10   0   0   0]\n",
      " [ 20  20   0 -20 -20   0   0   0]\n",
      " [ 30  30   0 -30 -30   0   0   0]\n",
      " [ 30  30   0 -30 -30   0   0   0]\n",
      " [ 30  30   0 -30 -30   0   0   0]\n",
      " [ 30  30   0 -30 -30   0   0   0]\n",
      " [ 20  20   0 -20 -20   0   0   0]\n",
      " [ 10  10   0 -10 -10   0   0   0]]\n",
      "sp_conv2dfull:\n",
      "[[ 10  10   0 -10 -10   0   0   0]\n",
      " [ 20  20   0 -20 -20   0   0   0]\n",
      " [ 30  30   0 -30 -30   0   0   0]\n",
      " [ 30  30   0 -30 -30   0   0   0]\n",
      " [ 30  30   0 -30 -30   0   0   0]\n",
      " [ 30  30   0 -30 -30   0   0   0]\n",
      " [ 20  20   0 -20 -20   0   0   0]\n",
      " [ 10  10   0 -10 -10   0   0   0]]\n",
      "np_fft_conv: \n",
      "[[ 10.  10.   0. -10. -10.  -0.   0.   0.]\n",
      " [ 20.  20.   0. -20. -20.  -0.   0.   0.]\n",
      " [ 30.  30.   0. -30. -30.  -0.   0.   0.]\n",
      " [ 30.  30.   0. -30. -30.  -0.   0.   0.]\n",
      " [ 30.  30.   0. -30. -30.  -0.   0.   0.]\n",
      " [ 30.  30.   0. -30. -30.  -0.   0.   0.]\n",
      " [ 20.  20.   0. -20. -20.  -0.   0.   0.]\n",
      " [ 10.  10.   0. -10. -10.  -0.   0.   0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NEGU93\\.conda\\envs\\tf-2-gpu\\lib\\site-packages\\ipykernel_launcher.py:51: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "img2 = np.array([\n",
    "    [10, 10, 10, 0, 0, 0],\n",
    "    [10, 10, 10, 0, 0, 0],\n",
    "    [10, 10, 10, 0, 0, 0],\n",
    "    [10, 10, 10, 0, 0, 0],\n",
    "    [10, 10, 10, 0, 0, 0],\n",
    "    [10, 10, 10, 0, 0, 0]\n",
    "]).astype(np.float64)\n",
    "k = np.array([\n",
    "        [1., 0., -1.],\n",
    "        [1., 0., -1.],\n",
    "        [1., 0., -1.]\n",
    "    ]).astype(np.float64)\n",
    "mode = 'full'\n",
    "\n",
    "conv = Convolutional(1, (3, 3), (6, 6, 1), padding=2, input_dtype=np.float32)\n",
    "conv.kernels = []\n",
    "conv.kernels.append(tf.reshape(tf.cast(tf.Variable(k, name=\"kernel\" + str(0) + \"_f\" + str(0)), dtype=np.float32),\n",
    "                               (3, 3, 1)))\n",
    "std_out = conv([img2])[..., 0]\n",
    "print(\"manual_conv: \\n\" + str(std_out.numpy()))\n",
    "\n",
    "img_tf = tf.constant(tf.reshape(img2, (1, 6, 6, 1)), dtype=tf.float64)\n",
    "k_tf = tf.constant(tf.reshape(k, (3, 3, 1, 1)), dtype=tf.float64)\n",
    "conv_tf = tf.nn.conv2d(img_tf, k_tf, strides=[1, 1], padding=\"SAME\")[0, ..., 0]\n",
    "print(\"tf_nn_conv2d: \\n\" + str(np.around(conv_tf.numpy())))\n",
    "# set_trace()\n",
    "\n",
    "img2_pad = tf.pad(img2.astype(np.float64), tf.constant([[0, 2], [0, 2]]))\n",
    "k_pad = tf.pad(k, tf.constant([[0, 5], [0, 5]]))\n",
    "I = tf.signal.fft2d(tf.cast(img2_pad, tf.complex128))\n",
    "print(I)\n",
    "K = tf.signal.fft2d(tf.cast(k_pad, tf.complex128))\n",
    "F = tf.math.multiply(I, K)\n",
    "f = tf.signal.ifft2d(F)\n",
    "f_real = tf.cast(f, tf.int32)\n",
    "print(\"manual_fft_conv: \" + str(f_real))\n",
    "\n",
    "np_fft_conv = np.array(signal.fftconvolve(img2, k, mode=mode) , np.int32)\n",
    "print(\"sp_fft_conv_\" + mode + \":\\n\" + str(np_fft_conv))\n",
    "\n",
    "np_conv = np.array(signal.convolve2d(img2 , k, mode), np.int32)\n",
    "print(\"sp_conv2d\" + mode + \":\\n\" + str(np_conv))\n",
    "\n",
    "# Check numpy implementation\n",
    "I = np.fft.fft2(img2_pad)\n",
    "K = np.fft.fft2(tf.pad(k, tf.constant([[0, 5], [0, 5]])))\n",
    "F = np.multiply(I, K)\n",
    "f = np.fft.ifft2(F)\n",
    "print(\"np_fft_conv: \\n\" + str(np.round(f.astype(np.float32))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 results here and they are:\n",
    "\n",
    "- $(x*v)(n) = \\sum x(m) \\, v(m)$\n",
    "- $(x*v)(n) = \\sum x(m) \\, v(n-m)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StackOverflow Example\n",
    "\n",
    "https://stackoverflow.com/questions/40703751/using-fourier-transforms-to-do-convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv:\n",
      " [[ 4  5  0  0  0]\n",
      " [ 3  0 -5  0  0]\n",
      " [ 0 -3  8 15  0]\n",
      " [ 0  0  9 16  5]\n",
      " [ 0  0  0  3  4]]\n",
      "manual fft method:\n",
      " [[ 4  5  0  0  0]\n",
      " [ 2  0 -5  0  0]\n",
      " [ 0 -3  8 15  0]\n",
      " [ 0  0  9 16  5]\n",
      " [ 0  0  0  3  4]]\n",
      "fft:\n",
      " [[ 3  5  0  0  0]\n",
      " [ 2  0 -5  0  0]\n",
      " [ 0 -2  8 15  0]\n",
      " [ 0  0  9 16  4]\n",
      " [ 0  0  0  2  4]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, 3, 0], [0, 0, 0, 1]])\n",
    "y = np.array([[4, 5], [3, 4]])\n",
    "\n",
    "print(\"conv:\\n\",  signal.convolve2d(x, y, 'full'))\n",
    "\n",
    "s1 = np.array(x.shape)\n",
    "s2 = np.array(y.shape)\n",
    "size = s1 + s2 - 1      # Full padding size = (5, 5)\n",
    "fsize = 2 ** np.ceil(np.log2(size)).astype(int)    # I do this to have a 2^n size to make fft faster\n",
    "# fsize = (8, 8)\n",
    "fslice = tuple([slice(0, int(sz)) for sz in size])  \n",
    "# slice to get the values later ([0:5], [0:5])\n",
    "\n",
    "new_x = np.fft.fft2(x, fsize)\n",
    "new_y = np.fft.fft2(y, fsize)\n",
    "result = np.fft.ifft2(new_x*new_y)[fslice].copy()\n",
    "\n",
    "print(\"manual fft method:\\n\", np.array(result.real, np.int32))\n",
    "\n",
    "print(\"fft:\\n\" , np.array(signal.fftconvolve(x, y), np.int32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Could not find valid device for node.\nNode:{{node Conv2D}}\nAll kernels registered for op Conv2D :\n  device='CPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_DOUBLE]\n  device='CPU'; T in [DT_INT32]\n  device='GPU'; T in [DT_HALF]\n  device='GPU'; T in [DT_FLOAT]\n  device='GPU'; T in [DT_DOUBLE]\n  device='GPU'; T in [DT_INT32]\n [Op:Conv2D]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8bd569e48878>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mc_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomplex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mc_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomplex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mconv_tf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"SAME\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv_tf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-2-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconv2d_v2\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1912\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m                 \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1914\u001b[1;33m                 name=name)\n\u001b[0m\u001b[0;32m   1915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-2-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\u001b[0m\n\u001b[0;32m   2009\u001b[0m                            \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m                            \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2011\u001b[1;33m                            name=name)\n\u001b[0m\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-2-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m    935\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 937\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    938\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-2-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6605\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6606\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6607\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-2-gpu\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Could not find valid device for node.\nNode:{{node Conv2D}}\nAll kernels registered for op Conv2D :\n  device='CPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_DOUBLE]\n  device='CPU'; T in [DT_INT32]\n  device='GPU'; T in [DT_HALF]\n  device='GPU'; T in [DT_FLOAT]\n  device='GPU'; T in [DT_DOUBLE]\n  device='GPU'; T in [DT_INT32]\n [Op:Conv2D]"
     ]
    }
   ],
   "source": [
    "img2 = np.array([\n",
    "    [10, 10, 10, 0, 0, 0],\n",
    "    [10, 10, 10, 0, 0, 0],\n",
    "    [10, 10, 10, 0, 0, 0],\n",
    "    [10, 10, 10, 0, 0, 0],\n",
    "    [10, 10, 10, 0, 0, 0],\n",
    "    [10, 10, 10, 0, 0, 0]\n",
    "]).astype(np.float64)\n",
    "k = np.array([\n",
    "        [1., 0., -1.],\n",
    "        [1., 0., -1.],\n",
    "        [1., 0., -1.]\n",
    "    ]).astype(np.float64)\n",
    "mode = 'full'\n",
    "\n",
    "c_img = tf.Variable(tf.complex(img2, img2))\n",
    "c_k = tf.Variable(tf.complex(k, np.zeros(k.shape)))\n",
    "conv_tf = tf.nn.conv2d(c_img, c_k, strides=[1, 1], padding=\"SAME\")[0, ..., 0]\n",
    "print(conv_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/47577458/complex-convolution-in-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow fftconv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def _centered(arr, newshape):\n",
    "    # Return the center newshape portion of the array.\n",
    "    currshape = tf.shape(arr)[-2:]\n",
    "    startind = (currshape - newshape) // 2\n",
    "    endind = startind + newshape\n",
    "    return arr[..., startind[0]:endind[0], startind[1]:endind[1]]\n",
    "\n",
    "def fftconv(in1, in2, mode=\"full\"):\n",
    "    mode = mode.lower()\n",
    "    # Reorder channels to come second (needed for fft)\n",
    "    in1 = tf.transpose(in1, perm=[0, 3, 1, 2])\n",
    "    in2 = tf.transpose(in2, perm=[0, 3, 1, 2])\n",
    "\n",
    "    # Extract shapes\n",
    "    s1 = tf.convert_to_tensor(tf.shape(in1)[-2:])\n",
    "    s2 = tf.convert_to_tensor(tf.shape(in2)[-2:])\n",
    "    shape = s1 + s2 - 1\n",
    "\n",
    "    # Compute convolution in fourier space\n",
    "    sp1 = tf.spectral.rfft2d(in1, shape)\n",
    "    sp2 = tf.spectral.rfft2d(in2, shape)\n",
    "    ret = tf.spectral.irfft2d(sp1 * sp2, shape)\n",
    "\n",
    "    # Crop according to mode\n",
    "    if mode == \"full\":\n",
    "        cropped = ret\n",
    "    elif mode == \"same\":\n",
    "        cropped = _centered(ret, s1)\n",
    "    elif mode == \"valid\":\n",
    "        cropped = _centered(ret, s1 - s2 + 1)\n",
    "    else:\n",
    "        raise ValueError(\"Acceptable mode flags are 'valid',\"\n",
    "                         \" 'same', or 'full'.\")\n",
    "\n",
    "    # Reorder channels to last\n",
    "    result = tf.transpose(cropped, perm=[0, 2, 3, 1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'spectral'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d63ab038e3b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0monv_tf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfftconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_tf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_tf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"SAME\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-ddb945a33b1e>\u001b[0m in \u001b[0;36mfftconv\u001b[1;34m(in1, in2, mode)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Compute convolution in fourier space\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0msp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspectral\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrfft2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0msp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspectral\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrfft2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspectral\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mirfft2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msp1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msp2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'spectral'"
     ]
    }
   ],
   "source": [
    "onv_tf = fftconv(img_tf, k_tf, mode=\"SAME\")[0, ..., 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
